#load libraries
library(reshape)
library(vegan)
library(bipartite)

setwd("C:/Users/utente/Desktop/networks")

#Calculate mean number of individuals between sampling rounds
carab.per.round = read.csv(file = "carab.per.round.csv", header = TRUE, sep = ";")
mean.carab=aggregate(carab.per.round[,3:ncol(carab.per.round)], list(carab.per.round$trap.code), mean)

#Export and reimport file to add a landscape column
write.table(mean.carab,file="mean.carab.csv",row.names=T,col.names=T,quote=F,sep=";")
mean.carab = read.csv(file = "mean.carab.csv", header = TRUE, sep = ";")

#Merge to add habitat data
trap.habitat = read.csv(file = "trap.habitat.csv", header = TRUE, sep = ";")
mean.carab.habitat<-merge(trap.habitat,mean.carab,  by="trap",all.y = FALSE)

#NMDS
library(ggpubr)
library(dplyr)
library(ecodist)

m.car=mean.carab.habitat
rownames(m.car)=m.car[,1]
m.car=m.car[,-(1:4)]

mds=m.car%>%
  distance(method="bray-curtis")%>%
  cmdscale(k=3)%>%
  as_tibble()%>%
  mutate(groups=mean.carab.habitat$Macrohabitat)
colnames(mds)=c("Dim.1","Dim.2","Dim.3","Habitat")

ggscatter(mds,x="Dim.1",y="Dim.2",
          color="Habitat",
          palette=c("darkgreen","green","lightgreen","blue","orange","yellow","red","lightblue"),
          pch=3,
          size=2,
          ellipse=TRUE,
          ellipse.type="confidence")
          
#Network loop
library(bipartite)

row.names(mean.carab.habitat)=mean.carab.habitat[,1]
net.list=split.data.frame(mean.carab.habitat, mean.carab.habitat$landscape)
rownames(net.list)=net.list[,1]

net_=list()

for (i in 1:length(net.list)){
  net_[[i]]=as.data.frame(networklevel(net.list[[i]][,-c(1:4)]))
}

names(net_)=names(net.list)

#Loop to export all of the output at once
for (i in seq_along(net_)) {
  filename = paste(names(net_)[i], ".csv")
  write.table(net_[[i]], filename,row.names=T,col.names=T,quote=F,sep=";")
}

#Loop for modularity

mod.list=list()
mod_=list()

for (i in 1:length(net.list)){
  mod.list[[i]]=computeModules(net.list[[i]][,-c(1:4)])
  mod_[[i]]=as.vector(mod.list[[i]]@likelihood)
}

write.table(mod_, "mod.csv",row.names=T,col.names=T,quote=F,sep=";")


#Mono-habitat networks (forest)

forest=subset(mean.carab.habitat,Macrohabitat=="Forest"| Macrohabitat=="Hedgerow")
forest=ceiling(forest[,-c(1:4)]) #Round the numbers, for the null models

for_=list()

for (i in 1:length(for.list)){
  for_[[i]]=as.data.frame(networklevel(for.list[[i]][,-c(1:4)]))
}

names(for_)=names(for.list)

#Null models (Tur method)

samples = read.csv(file = "samples.csv", header = TRUE, sep = ";")
samples=split.data.frame(samples, samples$Site)
samples=samples[-12] #removes W (but doesn't work either)

for (i in 1:length(net.list)){
  rownames(net.list[[i]])=paste(net.list[[i]][,2],".",net.list[[i]][,1])
} #change row names so that "grep" function works

net.list.round=list()

for (i in 1:length(net.list)){
  net.list.round[[i]]=ceiling(net.list[[i]][,-c(1:4)])
}

names(net.list.round)=names(net.list) #rounding numbers for the null models
networks_i_sp=net.list.round
networks_i_sp=networks_i_sp[-12] #removes W (but doesn't work either)

spp1<-list()
for (i in 1:length(samples)){
  spp1[[i]]<-as.character(subset(samples[[i]],samples[[i]]$no.ind==1)$Species)
}
spp1 # List of habitats in each site with only one patch sampled.

m1<-list()
for(n in 1:length(networks_i_sp)){
  subnetworks<-list()
  for (i in 1:length(spp1[[n]])){
    subnetworks[[i]]<-networks_i_sp[[n]][grep(spp1[[n]][i],rownames(networks_i_sp[[n]])),]
    m1[[n]]<-do.call(rbind,subnetworks)
  }
}
m1 # Matrices with habitats with only one patch sampled
spp2<-list()
for (i in 1:length(samples)){
  spp2[[i]]<-as.character(subset(samples[[i]],samples[[i]]$no.ind>1)$Species)
}
spp2 # List of habitats in each site with > 1 patch

subnetworks<-list()
for(n in 1:length(networks_i_sp)){
  m<-list()
  for (i in 1:length(spp2[[n]])){
    m[[i]]<-networks_i_sp[[n]][grep(spp2[[n]][i],rownames(networks_i_sp[[n]])),]
  }
  subnetworks[[n]]<-m
}
subnetworks # Submatrices i-sp for all species with > individual sampled.
NULL.networks<-list()
for(n in 1:length(subnetworks)){
  null.subnetworks<-list()
  # Generate 1,000 null i-sp submatrices for each species:
  for (i in 1:length(subnetworks[[n]])){
    null.subnetworks[[i]]<-nullmodel(subnetworks[[n]][[i]],N=1000,method=1) # method 1 = Fixed row and column totals.
    for(j in 1:1000){
      colnames(null.subnetworks[[i]][[j]])<-colnames(subnetworks[[n]][[i]])
      rownames(null.subnetworks[[i]][[j]])<-rownames(subnetworks[[n]][[i]])
    }
  }
  null.networks<-list()
  # Combine null i-sp submatrices to create the complete null i-sp networks
  for(j in 1:1000){
    m2<-list()
    null<-matrix()
    for (i in 1:length(null.subnetworks)){
      m2[[i]]<-null.subnetworks[[i]][[j]]
      null<-do.call(rbind,m2)
    }
    null.networks[[j]]<-rbind(m1[[n]],null)
    null.networks[[j]]<-null.networks[[j]][order(rownames(null.networks[[j]])),]
  }
  NULL.networks[[n]]<-null.networks
}

#NODF for null networks and obs data (Tur method)

NODF.null<-list()
for(n in 1:length(NULL.networks)){
  nodf.null<-c()
  for(i in 1:length(NULL.networks[[n]])){
    nodf.null[i]<- nestednodf(NULL.networks[[n]][[i]], weighted=FALSE)$statistic[3]
  }
  NODF.null[[n]]<-nodf.null
}
NODF.null

NODF<-list()
for (i in 1:length(networks_i_sp)){
  NODF[[i]]<-nestednodf(networks_i_sp[[i]], weighted=FALSE)
}
NODF


praw=list() #raw p value to compare obs and null values

for (i in 1:length(NODF)){
  praw[[i]]=sum(NODF.null[[i]]>NODF[[i]]$statistic[3])/length(NODF.null[[i]])
}

names(praw)=names(networks_i_sp)

names(NODF)=names(networks_i_sp)
names(NODF.null)=names(networks_i_sp)

plot(density(NODF.null$Z),xlim=c(min(NODF$Z$statistic[3],min(NODF.null$Z)),max(NODF$Z$statistic[3],max(NODF.null$Z))),main="Comparison of observed with null model Patefield")
abline(v=NODF$Z$statistic[3],col="red",lwd=2) #plot network Z

#H2 for null networks and obs data (Tur method)

H2.null<-list()
for(n in 1:length(NULL.networks)){
  h2.null<-c()
  for(i in 1:length(NULL.networks[[n]])){
    h2.null[i]<- networklevel(NULL.networks[[n]][[i]], index="H2")
  }
  H2.null[[n]]<-h2.null
}
H2.null

H2<-list()
for (i in 1:length(networks_i_sp)){
  H2[[i]]<-networklevel(networks_i_sp[[i]], index="H2")
}
H2


prawH2=list()

for (i in 1:length(H2)){
  prawH2[[i]]=sum(H2.null[[i]]>H2[[i]])/length(H2.null[[i]])
}

names(prawH2)=names(networks_i_sp)


names(H2)=names(networks_i_sp)
names(H2.null)=names(networks_i_sp)

plot(density(H2.null$Z),xlim=c(min(H2$Z,min(H2.null$Z)),max(H2$Z,max(H2.null$Z))),main="Comparison of observed with null model Patefield")
abline(v=H2$Z,col="red",lwd=2)

#Species-habitat networks: calculating the mean for each habitat type

mean.carab.habitat["landscape.habitat"]=paste(mean.carab.habitat$landscape,mean.carab.habitat$Habitat)
col_idx <- grep("landscape.habitat", names(mean.carab.habitat))
mean.carab.habitat <- mean.carab.habitat[, c(col_idx, (1:ncol(mean.carab.habitat))[-col_idx])]
mean.per.habitat=aggregate(mean.carab.habitat[,6:ncol(mean.carab.habitat)], list(mean.carab.habitat$landscape.habitat), mean)
habitat.type=unique(mean.carab.habitat[, c("landscape.habitat", "landscape","Habitat")])
colnames(habitat.type)[1]="Group.1"
mean.per.habitat<-merge(habitat.type,mean.per.habitat,  by="Group.1",all.y = FALSE)

#Network loop

library(bipartite)

row.names(mean.per.habitat)=mean.per.habitat[,1]
net.list=split.data.frame(mean.per.habitat, mean.per.habitat$landscape)


net_=list()

for (i in 1:length(net.list)){
  net_[[i]]=as.data.frame(networklevel(net.list[[i]][,-c(1:3)]))
}

names(net_)=names(net.list)

#Loop to export all of the output at once
for (i in seq_along(net_)) {
  filename = paste(names(net_)[i], ".csv")
  write.table(net_[[i]], filename,row.names=T,col.names=T,quote=F,sep=";")
}


#Loop for modularity
mod.list=list()
mod_=list()
for (i in 1:length(net.list)){
  mod.list[[i]]=computeModules(net.list[[i]][,-c(1:4)])
  mod_[[i]]=as.vector(mod.list[[i]]@likelihood)
}

write.table(mod_, "mod.csv",row.names=T,col.names=T,quote=F,sep=";")


#Pollinator script

setwd("C:/Users/utente/Desktop/networks")

#Calculate mean number of individuals between sampling rounds
pollinators = read.csv(file = "habitat.bees.marini.csv", header = TRUE, sep = ";")
poll.sum=aggregate(pollinators[,8:ncol(pollinators)], list(pollinators$name), sum)

#Export and reimport file to add a landscape column
write.table(poll.sum,file="poll.sum.csv",row.names=T,col.names=T,quote=F,sep=";")
poll.sum = read.csv(file = "poll.sum.1.csv", header = TRUE, sep = ";")

#Merge to add habitat data
trap.habitat = read.csv(file = "habitat.poll.csv", header = TRUE, sep = ";")
patch <-unique(trap.habitat[, c("Typ", "name")])
poll.sum.habitat<-merge(patch,poll.sum,  by="name",all.y = FALSE)

#NMDS
library(ggpubr)
library(dplyr)
library(ecodist)

m.car=poll.sum.habitat
rownames(m.car)=m.car[,1]
m.car=m.car[,-(1:3)]

mds=m.car%>%
  distance(method="bray-curtis")%>%
  cmdscale(k=3)%>%
  as_tibble()%>%
  mutate(groups=poll.sum.habitat$Typ)
colnames(mds)=c("Dim.1","Dim.2","Dim.3","Habitat")

ggscatter(mds,x="Dim.1",y="Dim.2",
          color="Habitat",
          palette=c("lightblue","darkgreen","blue","green","gold","grey"),
          pch=3,
          size=2,
          ellipse=TRUE,
          ellipse.type="confidence")
          
     #Network loop

library(bipartite)

row.names(poll.sum.habitat)=poll.sum.habitat[,1]
net.list=split.data.frame(poll.sum.habitat, poll.sum.habitat$landscape)


net_=list()

for (i in 1:length(net.list)){
  net_[[i]]=as.data.frame(networklevel(net.list[[i]][,-c(1:3)]))
}

names(net_)=names(net.list)

#Loop to export all of the output at once
for (i in seq_along(net_)) {
  filename = paste(names(net_)[i], ".csv")
  write.table(net_[[i]], filename,row.names=T,col.names=T,quote=F,sep=";")
}


#Loop for modularity
mod.list=list()
mod_=list()
for (i in 1:length(net.list)){
  mod.list[[i]]=computeModules(net.list[[i]][,-c(1:3)])
  mod_[[i]]=as.vector(mod.list[[i]]@likelihood)
}

write.table(mod_, "mod.csv",row.names=T,col.names=T,quote=F,sep=";")
     
          
          
#Cicadellidae script

setwd("C:/Users/utente/Desktop/networks")

#Calculate mean number of individuals between sampling rounds
cicaline = read.csv(file = "cica.per.round.csv", header = TRUE, sep = ";")
cica.sum=aggregate(cicaline[,5:ncol(cicaline)], list(cicaline$zone), sum)

#Export and reimport file to add a landscape column
write.table(cica.sum,file="cica.sum.csv",row.names=T,col.names=T,quote=F,sep=";")
cica.sum = read.csv(file = "cica.sum.1.csv", header = TRUE, sep = ";")

#Merge to add habitat data
trap.habitat = read.csv(file = "cica.habitat.csv", header = TRUE, sep = ";")
patch <-unique(trap.habitat[, c("zone", "habitat")])
cica.sum.habitat<-merge(patch,cica.sum,  by="zone",all.y = FALSE)

#NMDS
library(ggpubr)
library(dplyr)
library(ecodist)

m.car=cica.sum.habitat
rownames(m.car)=m.car[,1]
m.car=m.car[,-(1:3)]

mds=m.car%>%
  distance(method="bray-curtis")%>%
  cmdscale(k=3)%>%
  as_tibble()%>%
  mutate(groups=cica.sum.habitat$habitat)
colnames(mds)=c("Dim.1","Dim.2","Dim.3","Habitat")

ggscatter(mds,x="Dim.1",y="Dim.2",
          color="Habitat",
          palette=c("gold","darkgreen","green","lightblue","red"),
          pch=3,
          size=2,
          ellipse=TRUE,
          ellipse.type="confidence")

#Network loop

library(bipartite)

row.names(cica.sum.habitat)=cica.sum.habitat[,1]
net.list=split.data.frame(cica.sum.habitat, cica.sum.habitat$landscape)


net_=list()

for (i in 1:length(net.list)){
  net_[[i]]=as.data.frame(networklevel(net.list[[i]][,-c(1:3)]))
}

names(net_)=names(net.list)

#Loop to export all of the output at once
for (i in seq_along(net_)) {
  filename = paste(names(net_)[i], ".csv")
  write.table(net_[[i]], filename,row.names=T,col.names=T,quote=F,sep=";")
}


#Loop for modularity
mod.list=list()
mod_=list()
for (i in 1:length(net.list)){
  mod.list[[i]]=computeModules(net.list[[i]][,-c(1:3)])
  mod_[[i]]=as.vector(mod.list[[i]]@likelihood)
}

write.table(mod_, "mod.csv",row.names=T,col.names=T,quote=F,sep=";")

#Species-habitat networks: calculating the sum for each habitat type

cica.sum.habitat["landscape.habitat"]=paste(cica.sum.habitat$landscape,cica.sum.habitat$habitat)
col_idx <- grep("landscape.habitat", names(cica.sum.habitat))
cica.sum.habitat <- cica.sum.habitat[, c(col_idx, (1:ncol(cica.sum.habitat))[-col_idx])]
sum.per.habitat=aggregate(cica.sum.habitat[,5:ncol(cica.sum.habitat)], list(cica.sum.habitat$landscape.habitat), sum)
habitat.type=unique(cica.sum.habitat[, c("landscape.habitat", "landscape","habitat")])
colnames(habitat.type)[1]="Group.1"
sum.per.habitat<-merge(habitat.type,sum.per.habitat,  by="Group.1",all.y = FALSE)

#Network loop

library(bipartite)

row.names(sum.per.habitat)=sum.per.habitat[,1]
net.list=split.data.frame(sum.per.habitat, sum.per.habitat$landscape)


net_=list()

for (i in 1:length(net.list)){
  net_[[i]]=as.data.frame(networklevel(net.list[[i]][,-c(1:3)]))
}

names(net_)=names(net.list)

#Loop to export all of the output at once
for (i in seq_along(net_)) {
  filename = paste(names(net_)[i], ".csv")
  write.table(net_[[i]], filename,row.names=T,col.names=T,quote=F,sep=";")
}


#Loop for modularity
mod.list=list()
mod_=list()
for (i in 1:length(net.list)){
  mod.list[[i]]=computeModules(net.list[[i]][,-c(1:4)])
  mod_[[i]]=as.vector(mod.list[[i]]@likelihood)
}

write.table(mod_, "mod.csv",row.names=T,col.names=T,quote=F,sep=";")



####Species-level metrics (Cicadellidae - patch networks)

cica.sum = read.csv(file = "cica.sum.1.csv", header = TRUE, sep = ";")

#Merge to add habitat data
trap.habitat = read.csv(file = "cica.habitat.csv", header = TRUE, sep = ";")
patch <-unique(trap.habitat[, c("zone", "habitat")])
cica.sum.habitat<-merge(patch,cica.sum,  by="zone",all.y = FALSE)

library(bipartite)

row.names(cica.sum.habitat)=cica.sum.habitat[,1]
net.list=split.data.frame(cica.sum.habitat, cica.sum.habitat$landscape)


net_=list()

for (i in 1:length(net.list)){
  net_[[i]]=as.data.frame(specieslevel(net.list[[i]][,-c(1:3)],level="higher"))
}

names(net_)=names(net.list)


#Loop to export all of the output at once
for (i in seq_along(net_)) {
  filename = paste(names(net_)[i], ".csv")
  write.table(net_[[i]], filename,row.names=T,col.names=T,quote=F,sep=";")
}


####Specieslevel (carab)

mean.carab = read.csv(file = "mean.carab.csv", header = TRUE, sep = ";")

#Merge to add habitat data
trap.habitat = read.csv(file = "trap.habitat.csv", header = TRUE, sep = ";")
mean.carab.habitat<-merge(trap.habitat,mean.carab, by="trap",all.y = FALSE)

#Network loop
library(bipartite)

row.names(mean.carab.habitat)=mean.carab.habitat[,1]
net.list=split.data.frame(mean.carab.habitat, mean.carab.habitat$landscape)
rownames(net.list)=net.list[,1]

net_=list()

for (i in 1:length(net.list)){
  net_[[i]]=as.data.frame(specieslevel(net.list[[i]][,-c(1:5)],level="higher"))
}

names(net_)=names(net.list)

#Loop to export all of the output at once
for (i in seq_along(net_)) {
  filename = paste(names(net_)[i], ".csv")
  write.table(net_[[i]], filename,row.names=T,col.names=T,quote=F,sep=";")
}


#specieslevel carabidae (habitat level)

mean.carab.habitat["landscape.habitat"]=paste(mean.carab.habitat$landscape,mean.carab.habitat$Habitat)
col_idx <- grep("landscape.habitat", names(mean.carab.habitat))
mean.carab.habitat <- mean.carab.habitat[, c(col_idx, (1:ncol(mean.carab.habitat))[-col_idx])]
mean.per.habitat=aggregate(mean.carab.habitat[,7:ncol(mean.carab.habitat)], list(mean.carab.habitat$landscape.habitat), sum)
habitat.type=unique(mean.carab.habitat[, c("landscape.habitat", "landscape","Habitat")])
colnames(habitat.type)[1]="Group.1"
mean.per.habitat<-merge(habitat.type,mean.per.habitat,  by="Group.1",all.y = FALSE)

#Network loop

library(bipartite)

row.names(mean.per.habitat)=mean.per.habitat[,1]
net.list=split.data.frame(mean.per.habitat, mean.per.habitat$landscape)


net_=list()

for (i in 1:length(net.list)){
  net_[[i]]=as.data.frame(specieslevel(net.list[[i]][,-c(1:3)],level="higher"))
}

names(net_)=names(net.list)

#Loop to export all of the output at once
for (i in seq_along(net_)) {
  filename = paste(names(net_)[i], ".csv")
  write.table(net_[[i]], filename,row.names=T,col.names=T,quote=F,sep=";")
}
